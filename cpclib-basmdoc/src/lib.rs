pub mod cmdline;

use std::collections::HashMap;
use std::sync::Arc;

use cpclib_asm::{ListingElement, MayHaveSpan, parse_z80_str};
use cpclib_common::itertools::Itertools;
use minijinja::value::Object;
use minijinja::{Environment, ErrorKind, Value, context};
use rust_embed::Embed;
use serde::{Deserialize, Serialize};

// Include syntax highlighting keywords generated by build.rs
include!(concat!(env!("OUT_DIR"), "/syntax_keywords.rs"));

#[derive(Embed)]
#[folder = "src/templates/"]
#[include = "*.jinja"]
#[include = "*.js"]
#[include = "*.css"]
struct Templates;

const HIGHLIGHTJS_URL: &str = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js";
const HIGHLIGHTJS_CSS_URL: &str = "https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css";

/// Get cache directory for basmdoc assets
fn get_cache_dir() -> std::path::PathBuf {
    let cache_dir = dirs::cache_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("cpclib-basmdoc");
    
    std::fs::create_dir_all(&cache_dir).ok();
    cache_dir
}

/// Download a URL and cache it, or return cached content
fn download_or_cache(url: &str, filename: &str) -> Result<String, Box<dyn std::error::Error>> {
    let cache_file = get_cache_dir().join(filename);
    
    // Check if cached file exists
    if cache_file.exists() {
        return Ok(std::fs::read_to_string(&cache_file)?);
    }
    
    // Download the file
    let response = ureq::get(url).call()?;
    let content = response.into_string()?;
    
    // Cache it
    std::fs::write(&cache_file, &content).ok();
    
    Ok(content)
}

// Get highlight.js content (download once, then cache)
fn get_highlightjs() -> String {
    download_or_cache(HIGHLIGHTJS_URL, "highlight.min.js")
        .unwrap_or_else(|e| {
            eprintln!("Warning: Failed to download highlight.js: {}. Syntax highlighting will be disabled.", e);
            String::new()
        })
}

// Get atom-one-dark CSS content (download once, then cache)
fn get_highlightjs_css() -> String {
    download_or_cache(HIGHLIGHTJS_CSS_URL, "atom-one-dark.min.css")
        .unwrap_or_else(|e| {
            eprintln!("Warning: Failed to download highlight.js CSS: {}. Styling will be limited.", e);
            String::new()
        })
}

// Get documentation.js content from embedded templates
fn get_documentation_js() -> String {
    Templates::get("documentation.js")
        .map(|file| String::from_utf8_lossy(file.data.as_ref()).to_string())
        .unwrap_or_else(|| {
            eprintln!("Warning: Failed to load documentation.js");
            String::new()
        })
}

// Get documentation.css content from embedded templates
fn get_documentation_css() -> String {
    Templates::get("documentation.css")
        .map(|file| String::from_utf8_lossy(file.data.as_ref()).to_string())
        .unwrap_or_else(|| {
            eprintln!("Warning: Failed to load documentation.css");
            String::new()
        })
}

const GLOBAL_DOCUMENTATION_START: &str = ";;;";
const LOCAL_DOCUMENTATION_START: &str = ";;";

#[derive(Debug, Serialize, Deserialize, Clone)]
pub enum MetaDocumentation {
    Author(String),
    Date(String),
    Since(String)
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub enum DocumentedItem {
    File(String),
    Label(String),
    Equ(String, String),
    Macro { name: String, arguments: Vec<String>, content: String },
    Function { name: String, arguments: Vec<String>, content: String }
}

impl DocumentedItem {
    pub fn is_label(&self) -> bool {
        matches!(self, DocumentedItem::Label(_))
    }

    pub fn is_equ(&self) -> bool {
        matches!(self, DocumentedItem::Equ(_, _))
    }

    pub fn is_macro(&self) -> bool {
        matches!(self, DocumentedItem::Macro { .. })
    }

    pub fn is_function(&self) -> bool {
        matches!(self, DocumentedItem::Function { .. })
    }

    pub fn is_file(&self) -> bool {
        matches!(self, DocumentedItem::File(_))
    }

    pub fn item_key(&self) -> String {
        match self {
            DocumentedItem::Label(l) => {
                format!("label_{}", l)
            },

            DocumentedItem::Equ(l, _) => {
                format!("equ_{}", l)
            },

            DocumentedItem::Macro { name, .. } => {
                format!("macro_{}", name)
            },

            DocumentedItem::Function { name, .. } => {
                format!("function_{}", name)
            },

            DocumentedItem::File(fname) => {
                format!("file_{}", fname.replace(['/', '\\', '.'], "_"))
            }
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SymbolReference {
    pub source_file: String,
    pub line_number: usize,
    pub context: String // surrounding code for context
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ItemDocumentation {
    item: DocumentedItem,
    doc: String, // TODO use MetaDocumentation
    source_file: String,
    line_number: usize, // 1-indexed line number where the symbol is defined
    references: Vec<SymbolReference>
}

impl Object for ItemDocumentation {
    fn get_value(self: &Arc<Self>, key: &Value) -> Option<Value> {
        match key.as_str() {
            Some("doc") => Some(Value::from(self.doc.clone())),
            Some("summary") => Some(Value::from(self.item_long_summary())),
            Some("short_summary") => Some(Value::from(self.item_short_summary())),
            Some("key") => Some(Value::from(self.item.item_key())),
            Some("source_file") => Some(Value::from(self.source_file.clone())),
            Some("line_number") => Some(Value::from(self.line_number)),
            Some("references") => {
                // Convert references to a Value that can be used in templates
                let refs: Vec<Value> = self.references.iter().map(|r| {
                    Value::from_serialize(r)
                }).collect();
                Some(Value::from(refs))
            },
            Some("has_references") => Some(Value::from(!self.references.is_empty())),
            Some("source") => {
                if self.is_macro() {
                    Some(Value::from(self.macro_source()))
                } else if self.is_function() {
                    Some(Value::from(self.function_source()))
                } else {
                    Some(Value::from(String::new()))
                }
            },
            _ => None
        }
    }
}

impl ItemDocumentation {
    /// Get the source code of a macro, or empty string for other items
    pub fn macro_source(&self) -> String {
        match &self.item {
            DocumentedItem::Macro { content, .. } => content.clone(),
            _ => String::new()
        }
    }

    /// Get the source code of a function, or empty string for other items
    pub fn function_source(&self) -> String {
        match &self.item {
            DocumentedItem::Function { content, .. } => content.clone(),
            _ => String::new()
        }
    }

    delegate::delegate! {
        to self.item {
            pub fn is_label(&self) -> bool;
            pub fn is_equ(&self) -> bool;
            pub fn is_macro(&self) -> bool;
            pub fn is_function(&self) -> bool;
            pub fn is_file(&self) -> bool;

            pub fn item_key(&self) -> String;
        }
    }

    pub fn item_long_summary(&self) -> String {
        match &self.item {
            DocumentedItem::Label(l) => l.to_string(),

            DocumentedItem::Equ(l, v) => {
                format!("{l} EQU {v}")
            },

            DocumentedItem::Macro { name, arguments, .. } => {
                let args = arguments.join(",");
                format!("MACRO {name}({args})")
            },

            DocumentedItem::Function { name, arguments, .. } => {
                let args = arguments.join(",");
                format!("FUNCTION {name}({args})")
            },

            DocumentedItem::File(fname) => {
                format!("File: {}", fname)
            }
        }
    }

    pub fn item_short_summary(&self) -> String {
        match &self.item {
            DocumentedItem::Label(l) => l.to_string(),

            DocumentedItem::Equ(l, v) => {
                l.clone()
            },

            DocumentedItem::Macro { name, .. } => {
                name.clone()
            },

            DocumentedItem::Function { name, .. } => {
                name.clone()
            },

            DocumentedItem::File(fname) => {
                fname.clone()
            }
        }
    }

    pub fn to_markdown(&self) -> String {
        let mut md = String::default();

        match &self.item {
            DocumentedItem::Label(l) => {
                md += &format!("## {l} (label) \n\n");
            },

            DocumentedItem::Equ(l, v) => {
                md += &format!("## {l} EQU {v} \n\n");
            },

            DocumentedItem::Macro { name, arguments, .. } => {
                let args = arguments.join(",");
                md += &format!("## MACRO {name}({args}) \n\n");
            },

            DocumentedItem::Function { name, arguments, .. } => {
                let args = arguments.join(",");
                md += &format!("## FUNCTION {name}({args}) \n\n");
            },

            DocumentedItem::File(fname) => {
                md += &format!("## File: {fname} \n\n");
            }
        }

        md += &self.doc;
        md += "\n";

        md
    }
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DocumentationPage {
    fname: String,
    content: Vec<ItemDocumentation>,
    all_files: Vec<String>
}

impl Object for DocumentationPage {
    fn get_value(self: &Arc<Self>, name: &Value) -> Option<minijinja::value::Value> {
        match name.as_str() {
            Some("file_name") => Some(Value::from(self.fname.clone())),
            Some("file_list") => {
                let files = self.file_list()
                    .into_iter()
                    .map(Value::from)
                    .collect::<Vec<_>>();
                Some(Value::from(files))
            },
            Some("labels") => {
                let mut labels = self
                    .label_iter()
                    .cloned()
                    .collect::<Vec<_>>();
                labels.sort_by(|a, b| a.item_short_summary().cmp(&b.item_short_summary()));
                let labels = labels.into_iter().map(Value::from_object).collect::<Vec<_>>();
                let labels = Value::from_object(labels);
                Some(labels)
            },
            Some("macros") => {
                let mut macros = self
                    .macro_iter()
                    .cloned()
                    .collect::<Vec<_>>();
                macros.sort_by(|a, b| a.item_short_summary().cmp(&b.item_short_summary()));
                let macros = macros.into_iter().map(Value::from_object).collect::<Vec<_>>();
                let macros = Value::from_object(macros);
                Some(macros)
            },
            Some("equs") => {
                let mut equs = self
                    .equ_iter()
                    .cloned()
                    .collect::<Vec<_>>();
                equs.sort_by(|a, b| a.item_short_summary().cmp(&b.item_short_summary()));
                let equs = equs.into_iter().map(Value::from_object).collect::<Vec<_>>();
                let equs = Value::from_object(equs);
                Some(equs)
            },
            Some("functions") => {
                let mut functions = self
                    .function_iter()
                    .cloned()
                    .collect::<Vec<_>>();
                functions.sort_by(|a, b| a.item_short_summary().cmp(&b.item_short_summary()));
                let functions = functions.into_iter().map(Value::from_object).collect::<Vec<_>>();
                let functions = Value::from_object(functions);
                Some(functions)
            },
            Some("files") => {
                let files = self.merged_files()
                    .into_iter()
                    .map(Value::from_object)
                    .collect::<Vec<_>>();
                let files = Value::from_object(files);
                Some(files)
            },
            Some("symbol_index") => {
                let index = self.symbol_index();
                let index_data: Vec<_> = index.into_iter().map(|(letter, items)| {
                    let items_vec: Vec<_> = items.into_iter()
                        .map(|item| Value::from_object(item.clone()))
                        .collect();
                    minijinja::value::Value::from_serialize(&(letter.to_string(), items_vec))
                }).collect();
                Some(Value::from(index_data))
            },
            _ => None
        }
    }

    fn call_method(
        self: &std::sync::Arc<Self>,
        _state: &minijinja::State<'_, '_>,
        method: &str,
        _args: &[minijinja::Value]
    ) -> Result<minijinja::Value, minijinja::Error> {
        match method {
            "has_labels" => Ok(Value::from(self.has_labels())),
            "has_macros" => Ok(Value::from(self.has_macros())),
            "has_equ" => Ok(Value::from(self.has_equ())),
            "has_functions" => Ok(Value::from(self.has_functions())),
            "has_files" => Ok(Value::from(self.has_files())),

            _ => {
                Err(minijinja::Error::new(
                    ErrorKind::UnknownMethod,
                    format!("Unknown method '{}'", method)
                ))
            },
        }
    }
}
impl DocumentationPage {
    // TODO handle errors
    pub fn for_file(fname: &str, display_name: &str, include_undocumented: bool) -> Result<Self, String> {
        let code = std::fs::read_to_string(fname)
            .map_err(|e| format!("Unable to read {} file. {}", fname, e))?;
        let tokens = parse_z80_str(&code).map_err(|e| format!("Unable to read source. {}", e))?;
        let doc = aggregate_documentation_on_tokens(&tokens, include_undocumented);

        let mut page = build_documentation_page_from_aggregates(display_name, doc);
        page.all_files = vec![display_name.to_string()];
        
        // Populate cross-references
        page = populate_cross_references(page, &tokens);
        
        Ok(page)
    }

    /// Merge multiple documentation pages into a single page
    pub fn merge(pages: Vec<Self>) -> Self {
        if pages.is_empty() {
            return Self {
                fname: String::from("Empty documentation"),
                content: Vec::new(),
                all_files: Vec::new()
            };
        }

        if pages.len() == 1 {
            return pages.into_iter().next().unwrap();
        }

        let fnames = pages.iter()
            .map(|p| p.fname.as_str())
            .collect::<Vec<_>>()
            .join(", ");
        
        let mut all_files: Vec<String> = pages.iter()
            .flat_map(|p| p.all_files.iter().cloned())
            .collect();
        all_files.sort();
        all_files.dedup();
        
        let content = pages.into_iter()
            .flat_map(|p| p.content)
            .collect();

        Self {
            fname: fnames,
            content,
            all_files
        }
    }

    pub fn label_iter(&self) -> impl Iterator<Item = &ItemDocumentation> {
        self.content.iter().filter(|item| item.is_label())
    }

    pub fn macro_iter(&self) -> impl Iterator<Item = &ItemDocumentation> {
        self.content.iter().filter(|item| item.is_macro())
    }

    pub fn equ_iter(&self) -> impl Iterator<Item = &ItemDocumentation> {
        self.content.iter().filter(|item| item.is_equ())
    }

    pub fn function_iter(&self) -> impl Iterator<Item = &ItemDocumentation> {
        self.content.iter().filter(|item| item.is_function())
    }

    pub fn file_iter(&self) -> impl Iterator<Item = &ItemDocumentation> {
        self.content.iter().filter(|item| item.is_file())
    }

    /// Get file documentation items merged by source file
    /// Multiple file-level doc comments from the same file are combined into one item
    pub fn merged_files(&self) -> Vec<ItemDocumentation> {
        let mut file_docs: std::collections::HashMap<String, Vec<String>> = std::collections::HashMap::new();
        
        // Group documentation by source file
        for item in self.file_iter() {
            file_docs
                .entry(item.source_file.clone())
                .or_insert_with(Vec::new)
                .push(item.doc.clone());
        }
        
        // Create merged ItemDocumentation for each file
        let mut merged: Vec<ItemDocumentation> = file_docs
            .into_iter()
            .map(|(source_file, docs)| {
                ItemDocumentation {
                    item: DocumentedItem::File(source_file.clone()),
                    doc: docs.join("\n\n"),
                    source_file,
                    line_number: 0, // File-level documentation doesn't have a specific line
                    references: Vec::new()
                }
            })
            .collect();
        
        // Sort by source file name
        merged.sort_by(|a, b| a.source_file.cmp(&b.source_file));
        merged
    }

    /// Get all symbols (labels, macros, functions, equs) for cross-referencing
    pub fn all_symbols(&self) -> Vec<(String, String)> {
        let mut symbols = Vec::new();
        
        for item in &self.content {
            if !item.is_file() {
                symbols.push((item.item_short_summary(), item.item.item_key()));
            }
        }
        
        symbols
    }

    /// Get alphabetically grouped symbols for index page
    pub fn symbol_index(&self) -> Vec<(char, Vec<&ItemDocumentation>)> {
        use std::collections::BTreeMap;
        
        let mut index: BTreeMap<char, Vec<&ItemDocumentation>> = BTreeMap::new();
        
        for item in &self.content {
            if !item.is_file() {
                let name = item.item_short_summary();
                if let Some(first_char) = name.chars().next() {
                    let key = first_char.to_ascii_uppercase();
                    index.entry(key).or_insert_with(Vec::new).push(item);
                }
            }
        }
        
        index.into_iter().collect()
    }

    pub fn has_labels(&self) -> bool {
        self.label_iter().next().is_some()
    }

    pub fn has_macros(&self) -> bool {
        self.macro_iter().next().is_some()
    }

    pub fn has_equ(&self) -> bool {
        self.equ_iter().next().is_some()
    }

    pub fn has_functions(&self) -> bool {
        self.function_iter().next().is_some()
    }

    pub fn has_files(&self) -> bool {
        self.file_iter().next().is_some()
    }

    /// Get a sorted list of unique source files
    pub fn file_list(&self) -> Vec<String> {
        self.all_files.clone()
    }

    /// Return a string that encode the documentation page in markdown
    pub fn to_markdown(&self) -> String {
        let page = Value::from_object(self.clone());

        let mut env = Environment::new();
        const TMPL_NAME: &str = "markdown_documentation.jinja";
        let tmpl_src = Templates::get(TMPL_NAME).expect("Template not found").data;
        let tmpl_src = std::str::from_utf8(tmpl_src.as_ref()).unwrap();
        env.add_template(TMPL_NAME, tmpl_src).unwrap();

        let tmpl = env.get_template("markdown_documentation.jinja").unwrap();
        tmpl.render(context! {
            page
        })
        .unwrap()
    }

    /// Return a string that encode the documentation page in HTML
    pub fn to_html(&self) -> String {
        let page = Value::from_object(self.clone());

        let mut env = Environment::new();
        
        // Add a custom filter to convert markdown to HTML
        env.add_filter("markdown_to_html", |value: String| -> Result<String, minijinja::Error> {
            use pulldown_cmark::{Parser, Options, html};
            
            let mut options = Options::empty();
            options.insert(Options::ENABLE_TABLES);
            options.insert(Options::ENABLE_FOOTNOTES);
            options.insert(Options::ENABLE_STRIKETHROUGH);
            options.insert(Options::ENABLE_TASKLISTS);
            
            let parser = Parser::new_ext(&value, options);
            let mut html_output = String::new();
            html::push_html(&mut html_output, parser);
            
            Ok(html_output)
        });
        
        // Add a basename filter to extract filename from path
        env.add_filter("basename", |value: String| -> Result<String, minijinja::Error> {
            use std::path::Path;
            let path = Path::new(&value);
            Ok(path.file_name()
                .and_then(|s| s.to_str())
                .unwrap_or(&value)
                .to_string())
        });
        
        // Capture symbols for cross-referencing
        let symbols = self.all_symbols();
        
        // Add a cross-reference filter to auto-link symbol names
        env.add_filter("auto_link_symbols", move |value: String| -> Result<String, minijinja::Error> {
            let mut result = value.clone();
            
            // Sort symbols by length (longest first) to avoid partial matches
            let mut sorted_symbols = symbols.clone();
            sorted_symbols.sort_by(|a, b| b.0.len().cmp(&a.0.len()));
            
            for (name, key) in sorted_symbols {
                // Only replace whole words (surrounded by word boundaries)
                let pattern = format!(r"\b{}\b", regex::escape(&name));
                if let Ok(re) = regex::Regex::new(&pattern) {
                    let replacement = format!("<a href=\"#{}\" class=\"symbol-link\">{}</a>", key, name);
                    result = re.replace_all(&result, replacement.as_str()).to_string();
                }
            }
            
            Ok(result)
        });
        
        const TMPL_NAME: &str = "html_documentation.jinja";
        let tmpl_src = Templates::get(TMPL_NAME).expect("Template not found").data;
        let tmpl_src = std::str::from_utf8(tmpl_src.as_ref()).unwrap();
        env.add_template(TMPL_NAME, tmpl_src).unwrap();

        // Add embedded assets as globals
        env.add_global("highlightjs", get_highlightjs());
        env.add_global("highlightjs_css", get_highlightjs_css());
        env.add_global("documentation_js", get_documentation_js());
        env.add_global("documentation_css", get_documentation_css());
        
        // Add syntax highlighting keywords
        env.add_global("syntax_instructions", SYNTAX_INSTRUCTIONS);
        env.add_global("syntax_directives", SYNTAX_DIRECTIVES);

        let tmpl = env.get_template("html_documentation.jinja").unwrap();
        tmpl.render(context! {
            page
        })
        .unwrap()
    }
}

#[inline]
pub fn is_any_documentation<T: ListingElement>(token: &T) -> bool {
    token.is_comment() && token.comment().starts_with(LOCAL_DOCUMENTATION_START)
}

#[inline]
pub fn is_global_documentation<T: ListingElement>(token: &T) -> bool {
    token.is_comment() && token.comment().starts_with(GLOBAL_DOCUMENTATION_START)
}

#[inline]
pub fn is_local_documentation<T: ListingElement>(token: &T) -> bool {
    token.is_comment()
        && token.comment().starts_with(LOCAL_DOCUMENTATION_START)
        && !token.comment().starts_with(GLOBAL_DOCUMENTATION_START)
}

pub fn is_documentable<T: ListingElement + ToString>(token: &T) -> bool {
    documentation_type(token, None).is_some()
}

pub fn documentation_type<T: ListingElement + ToString>(token: &T, last_global_label: Option<&str>) -> Option<DocumentedItem> {
    if token.is_label() {
        let label = token.label_symbol().to_string();
        // Handle local labels (starting with ".")
        if label.starts_with('.') {
            // If we have a parent global label, prepend it
            if let Some(parent) = last_global_label {
                Some(DocumentedItem::Label(format!("{}{}", parent, label)))
            } else {
                // No parent label, return the local label as-is (will be filtered later)
                Some(DocumentedItem::Label(label))
            }
        } else {
            // Regular global label
            Some(DocumentedItem::Label(label))
        }
    }
    else if token.is_equ() {
        Some(DocumentedItem::Equ(
            token.equ_symbol().to_string(),
            token.equ_value().to_string()
        ))
    }
    else if token.is_function_definition() {
        Some(DocumentedItem::Function {
            name: token.function_definition_name().to_string(),
            arguments: token
                .function_definition_params()
                .iter()
                .map(|a| a.to_string())
                .collect(),
            content: token.to_string()
        })
    }
    else if token.is_macro_definition() {
        Some(DocumentedItem::Macro {
            name: token.macro_definition_name().to_string(),
            arguments: token
                .macro_definition_arguments()
                .iter()
                .map(|a| a.to_string())
                .collect(),
            content: token.to_string() /*token.macro_definition_code().to_string()*/
        })
    }
    else {
        None
    }
}

pub fn build_documentation_page_from_aggregates<T: ListingElement + ToString>(
    fname: &str,
    agg: Vec<(String, Option<&T>, Option<String>, usize)>
) -> DocumentationPage {
    let content = agg
        .into_iter()
        .filter_map(|(doc, t, last_global_label, line_number)| {
            if let Some(t) = t {
                documentation_type(t, last_global_label.as_deref()).map(|item| {
                    ItemDocumentation {
                        item,
                        doc,
                        source_file: fname.to_string(),
                        line_number,
                        references: Vec::new()
                    }
                })
            }
            else {
                Some(ItemDocumentation {
                    item: DocumentedItem::File(fname.to_string()),
                    doc,
                    source_file: fname.to_string(),
                    line_number, // Use provided line number (typically 0 for file-level docs)
                    references: Vec::new()
                })
            }
        })
        .collect();

    DocumentationPage {
        fname: fname.to_string(),
        content,
        all_files: Vec::new() // Will be populated by for_file
    }
}

/// Aggregate the comments when there are considered to be documentation and associate them to the required token if any
/// Local labels (starting with ".") are resolved using the tracked parent global label
/// Returns: (doc_string, token_ref, parent_label, line_number)
pub fn aggregate_documentation_on_tokens<T: ListingElement + ToString + MayHaveSpan>(
    tokens: &[T],
    include_undocumented: bool
) -> Vec<(String, Option<&T>, Option<String>, usize)> {
    #[derive(PartialEq, Debug, Default, Clone, Copy)]
    enum CommentKind {
        #[default]
        Unspecified,
        Global,
        Local
    }

    #[derive(Default)]
    struct CommentInConstruction {
        kind: CommentKind,
        content: String
    }

    impl CommentInConstruction {
        fn consume(&mut self) -> String {
            self.kind = CommentKind::Unspecified;
            let comment = self.content.clone();
            self.content.clear();
            comment
        }

        fn clear(&mut self) {
            let _ = self.consume();
        }

        fn kind(&self) -> CommentKind {
            self.kind
        }

        fn set_kind(&mut self, kind: CommentKind) {
            self.kind = kind;
        }

        fn is_local(&self) -> bool {
            self.kind() == CommentKind::Local
        }

        fn is_global(&self) -> bool {
            self.kind() == CommentKind::Global
        }

        fn is_unspecified(&self) -> bool {
            self.kind() == CommentKind::Unspecified
        }

        fn add_comment(&mut self, comment: &str) {
            if !self.content.is_empty() {
                self.content += "\n";
            }

            // remove the ; that encode the documentation
            let comment = if self.is_global() {
                &comment[3..]
            }
            else {
                debug_assert!(self.is_local());
                &comment[2..]
            };

            // remove very first space if any
            let comment = if let Some(' ') = comment.chars().next() {
                &comment[1..]
            }
            else {
                comment
            };
            self.content += comment;
        }
    }

    let mut doc = Vec::new();

    let mut in_process_comment = CommentInConstruction::default();
    let mut last_global_label: Option<String> = None;

    for token in tokens {
        let (current_is_doc, current_is_documentable) = if is_global_documentation(token) {
            if in_process_comment.is_local() {
                // here, this is an error, there was a local comment and it is replaced by a global one
                // so, we lost it
                in_process_comment.clear();
            }
            in_process_comment.set_kind(CommentKind::Global);
            (true, false)
        }
        else if is_local_documentation(token) {
            if in_process_comment.is_global() {
                // here we can release the global comment
                doc.push((in_process_comment.consume(), None, None, 0));
            }
            in_process_comment.set_kind(CommentKind::Local);
            (true, false)
        }
        else {
            (false, is_documentable(token))
        };

        // Track the last global label for local label resolution
        if token.is_label() {
            let label = token.label_symbol().to_string();
            if !label.starts_with('.') {
                last_global_label = Some(label);
            }
        }

        if current_is_doc {
            // we update the documentation
            in_process_comment.add_comment(token.comment());
        }
        else if current_is_documentable {
            // Skip local labels without a parent
            let is_local_label = token.is_label() && token.label_symbol().starts_with('.');
            let should_skip = is_local_label && last_global_label.is_none();
            
            if !should_skip {
                let line_number = token.span().location_line() as usize;
                if !in_process_comment.is_unspecified() {
                    // we comment an item if any
                    let documented = if in_process_comment.is_global() {
                        // for a global comment, we do not care of that
                        None
                    }
                    else {
                        // but we do for a local comment
                        Some(token)
                    };
                    doc.push((in_process_comment.consume(), documented, last_global_label.clone(), line_number));
                }
                else if include_undocumented && (token.is_macro_definition() || token.is_function_definition()) {
                    // Include undocumented macros and functions if flag is set
                    doc.push((String::new(), Some(token), None, line_number));
                }
                else {
                    // we add no comment, so we do nothing
                }
            }
        }
        else {
            // this is not a doc or a documentable, so we can eventually treat a global
            if in_process_comment.is_global() {
                // For file-level documentation, line_number is 0 (or could be 1)
                doc.push((in_process_comment.consume(), None, None, 0));
            }
            else if in_process_comment.is_local() {
                // comment is lost as there is nothing else to comment
                in_process_comment.clear();
            }
        }
    }

    // The last comment can only be a global comment
    if in_process_comment.is_global() {
        doc.push((in_process_comment.consume(), None, None, 0));
    }

    doc
}

/// Extract symbols used in a token's expressions
fn extract_symbols_from_token<T: ListingElement + std::fmt::Display>(token: &T) -> Vec<String> {
    // Skip comments and label definitions (they're not references)
    if token.is_comment() || token.is_label() || token.is_macro_definition() {
        return Vec::new();
    }
    
    // Use the proper symbols() method from ListingElement
    token.symbols().into_iter().collect()
}

/// Collect cross-references by analyzing which symbols are used in which locations
pub fn collect_cross_references<T: ListingElement + std::fmt::Display>(
    tokens: &[T],
    source_file: &str
) -> HashMap<String, Vec<SymbolReference>> {
    let mut references: HashMap<String, Vec<SymbolReference>> = HashMap::new();
    
    for (line_num, token) in tokens.iter().enumerate() {
        let symbols = extract_symbols_from_token(token);
        let context = token.to_string();
        
        // Limit context length to avoid huge strings (char boundary-safe)
        let context = if context.chars().count() > 100 {
            let truncated: String = context.chars().take(100).collect();
            format!("{}...", truncated)
        } else {
            context
        };
        
        for symbol in symbols {
            references
                .entry(symbol)
                .or_insert_with(Vec::new)
                .push(SymbolReference {
                    source_file: source_file.to_string(),
                    line_number: line_num + 1, // 1-indexed for display
                    context: context.clone()
                });
        }
    }
    
    references
}

/// Populate cross-references in documentation page
pub fn populate_cross_references<T: ListingElement + std::fmt::Display>(mut page: DocumentationPage, tokens: &[T]) -> DocumentationPage {
    // Collect all references from tokens
    let all_refs = collect_cross_references(tokens, &page.fname);
    
    // Match references to documented items
    for item in &mut page.content {
        let symbol_name = item.item_short_summary();
        
        if let Some(refs) = all_refs.get(&symbol_name) {
            item.references.extend(refs.clone());
        }
    }
    
    page
}

#[cfg(test)]
mod test {
    use cpclib_asm::Token;

    use crate::{aggregate_documentation_on_tokens, is_any_documentation};

    #[test]
    fn test_is_documentation() {
        assert!(!is_any_documentation(&Token::Comment(
            "; any comment".into()
        )));
        assert!(is_any_documentation(&Token::Comment(
            ";; any comment".into()
        )));
        assert!(is_any_documentation(&Token::Comment(
            ";;; any comment".into()
        )));
    }

    #[test]
    fn test_aggregate_global_documentation() {
        let tokens = [
            Token::Comment(";;; This file is commented, not the function!".into()),
            Token::Label("my_function".into())
        ];
        let doc = aggregate_documentation_on_tokens(&tokens, false);
        assert_eq!(doc.len(), 1);
        assert_eq!(&doc[0].0, "This file is commented, not the function!");
        assert!(doc[0].1.is_none());
    }

    #[test]
    fn test_aggregate_global_documentation_followed_by_comment() {
        let tokens = [
            Token::Comment(";;; The aim of this file is to do stuffs.".into()),
            Token::Comment(";;; And this comment is a top file comment.".into()),
            Token::Comment("; This is not a documentation, just a comment".into())
        ];
        let doc = aggregate_documentation_on_tokens(&tokens, false);
        assert_eq!(doc.len(), 1);
        assert_eq!(
            &doc[0].0,
            "The aim of this file is to do stuffs.\nAnd this comment is a top file comment."
        );
        assert!(doc[0].1.is_none());
    }

    #[test]
    fn test_aggregate_label_comment() {
        let tokens = [
            Token::Comment(";; This function does something".into()),
            Token::Label("my_function".into())
        ];
        let doc = aggregate_documentation_on_tokens(&tokens, false);
        assert_eq!(doc.len(), 1);
        assert_eq!(&doc[0].0, "This function does something");
        assert!(doc[0].1.is_some());
    }

    #[test]
    fn test_aggregate_label_merged_comment() {
        let tokens = [
            Token::Comment(";; This function does something ...".into()),
            Token::Comment(";; ... on two lines".into()),
            Token::Label("my_function".into())
        ];
        let doc = aggregate_documentation_on_tokens(&tokens, false);
        assert_eq!(doc.len(), 1);
        assert_eq!(
            &doc[0].0,
            "This function does something ...\n... on two lines"
        );
        assert!(doc[0].1.is_some());
    }

    #[test]
    fn test_aggregate_macro_comment() {
        let tokens = [
            Token::Comment(";; This macro does something".into()),
            Token::Macro {
                name: "macro_name".into(),
                params: Vec::new(),
                content: "".into(),
                tokenized_content: Default::default(),
                flavor: cpclib_asm::AssemblerFlavor::Basm
            }
        ];
        let doc = aggregate_documentation_on_tokens(&tokens, false);
        assert_eq!(doc.len(), 1);
        assert_eq!(&doc[0].0, "This macro does something");
        assert!(doc[0].1.is_some());
    }
}
